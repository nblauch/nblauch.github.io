---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

How do brains enable organisms to learn from observing and interacting with the world?  How do their architectural constraints shape this learning and the structure of emergent neural representations? How can artificial intelligence inform our understanding of biological intelligence, and vice-versa?

These are some of the questions I am working on as a Postdoctoral Fellow in the [Harvard Vision Sciences Lab](https://konklab.fas.harvard.edu/#), in the [Psychology Department](https://psychology.fas.harvard.edu/) and [Kempner Institute for Natural and Artificial Intelligence](https://kempnerinstitute.harvard.edu/). I am primarily advised by [Talia Konkle](https://konklab.fas.harvard.edu), and collaborate with [George Alvarez](https://visionlab.harvard.edu/george/) and others in the Vision Sciences Lab, along with [Hanspeter Pfister](https://seas.harvard.edu/person/hanspeter-pfister) and others in the [Visual Computing Group](https://vcg.seas.harvard.edu/). Currently, I am focused on developing computational vision models that learn to see more like humans, and can provide greater insights into the neural computations underlying high-level vision. A particular active interest is *foveation*, whereby the human retina over-samples in the center of gaze (fovea), leading to a systematic over-representation of the fovea in the retinotopic maps of the visual cortex. I am currently studying how this affects high-level vision -- providing efficient sampling, demanding active mechanisms, and providing particular signals for self-supervised learning -- as well as the organization of high-level visual cortex -- with the retinotopic organization scaffolding all later processes. Here, as in my prior work, I am using the modern AI toolkit to implement classic and new ideas from neuroscience and cognitive science, in order to make theoretical scientific advances. 

I received my Ph.D in Neural Computation from Carnegie Mellon University in December 2023, where I was advised by [David C. Plaut](https://www.cnbc.cmu.edu/~plaut/) and [Marlene Behrmann](https://www.behrmannlab.pitt.edu/). My Ph.D work involved the development of computational models of [familiar and unfamiliar face recognition](/publication/cognition2020), and of [cortical organization for visual domains](/publication/pnas2022), as well as empirical investigations into the [hemispheric organization of high-level visual cortex](/publication/imagingneuro2025). 

Much of my research continues to build upon the topographic models I developed in my PhD, for example extending it to account for the [influence of retinotopy and language on the global organization](/projects/OHBM2022) of human ventral temporal cortex, and in modeling the spatial organization of language processing through [topographic Transformer language models](/publication/iclr2024) (see also our newer work: [topoLM](/publication/iclr2025)). I see this work as a set of critical first steps towards the development of large-scale functional models of the human brain, a challenging task which will unfold over the next few decades. 

Practically, my work aims to be useful for building efficient, sustainable AI; as impressive as it is, AI is currently orders of magnitude less energetically efficient than the human brain, which runs on ~20 watts. The spatial embedding of neural computations seems to be a key motif that may contribute to the brain's remarkable energetic efficiency. 

 <!-- simulations of which can help us both better understand the neurobiological basis of cognition and behavior, and aid neurotechnological interventions, such as predicting the effects of surgical resection or enhancing recovery from damage. -->


<!-- A good (albeit somewhat dated) introduction to this modeling work is a talk from Vision Sciences Society 2021 Conference, below. Ongoing work has built a 2-hemisphere version of this model that aims to account for the hemispheric organization of words and faces, among other object domains (see poster from [OHBM 2022](/projects/OHBM2022)).



{% include youtubePlayer.html id="MIdtuxfypSA" %}

<!-- <br style="clear:both" /> -->
<!-- <p align="left">
  <img width="300" src="/images/Neuroscience_Institute_Black.png" alt="NI" style="margin-right: 20px">
  <img width="100" src="/images/CMNI_Logo_Red.png" alt="NI2" style="margin-left: 20px">
  <br>
</p>  -->

<!-- ---   
# Publications and Pre-prints
<img align="left" src="/images/autism_pic.png" width="150" style="margin-right:10px"/> <b>[Uncharacteristic task-evoked pupillary responses implicate atypical locus coeruleus activity in autism](https://www.biorxiv.org/content/10.1101/863928v1.abstract)</b> <br>
Michael C. Granovetter, Charlie S. Burlingham, <b>Nicholas M. Blauch</b>, Nancy J. Minshaw, David J. Heeger, Marlene Behrmann (2019). <i>bioRXiv</i>.

<br style="clear:both" />
<br>
<img align="left" src="/images/ccn2019_pic.png" width="150" style="margin-right:10px"/> <b>[Computational insights into human expertise for familiar and unfamiliar face recognition](/publication/psyarxiv2019)</b> <br>
<b>Nicholas M. Blauch</b>, Marlene Behrmann, David C. Plaut. (2019). <i>PsyArxiv</i>.

<br style="clear:both" />
<br>
<img align="left" src="/images/nhb2019_pic.png" width="150" style="margin-right:10px"/> <b>[Representing Faces in 3D](/publication/nhb2019)</b> <br>
<b>Nicholas M. Blauch</b>, Marlene Behrmann. (2019)\\
<i>Nature Human Behavior</i>.

<br style="clear:both" />
<br>
<img align="left" src="/images/cogsci2017_pic.png" width="150" style="margin-right:10px"/> <b>[Functionally localized representations contain distributed information: insights from simulations of deep convolutional neural networks](/publication/cogsci2017)</b> <br>
<b>Nicholas M. Blauch</b>, Elissa Aminoff, Michael J. Tarr. (2017)\\
<i>39th Annual Proceedings of the Cognitive Science Society</i>, London U.K.
<br style="clear:both" />

---   
# Conference Presentations
<img align="left" src="/images/ccn2019_pic.png" width="150" style="margin-right:10px"/> <b>[Visual expertise and the familiar face advantage](/projects/CCN2019)</b> <br>
<b>Nicholas M. Blauch</b>, Marlene Behrmann, David Plaut.\\
Poster at <b>Cognitive Computational Neuroscience 2019</b>, Berlin Germany.

<br style="clear:both" />
<br>
<img align="left" src="/images/vss2019_pic.png" width="150" style="margin-right:10px"/> <b>[Assessing the similarity of object and scene representations through cross-validated voxel encoding models](/projects/VSS2019)</b> <br>
<b>Nicholas M. Blauch</b>, Filipe De Avile Belbute Peres, Alireza Chaman Zar, Juhi Farooqui, David Plaut, Marlene Behrmann. \\
Poster at <b>Vision Sciences 2019</b>, St. Pete Beach, FL.

<br style="clear:both" />
<br>
<img align="left" src="/images/ccn2018_pic.png" width="150" style="margin-right:10px"/> <b>[Task and stimulus normalization effects in face perception: an fMRI study](/projects/CCN2018)</b> <br>
<b>Nicholas M. Blauch</b>, Rosemary A. Cowell.\\
Poster at <b>Cognitive Computational Neuroscience 2018</b>, Philadelphia, PA.

<br style="clear:both" />
<br>
<img align="left" src="/images/cogsci2017_pic.png" width="150" style="margin-right:10px"/> <b>[Functionally localized representations contain distributed information](/talks/cogsci2017)</b> <br>
<b>Nicholas M. Blauch</b>, Elissa Aminoff, Michael J. Tarr.\\
Talk at <b>Cognitive Science 2017</b>, London, U.K.

<br style="clear:both" /> -->
---   
<br>
<p align="center">
  <img width="300" src="/images/brain.png" alt="Me" style="margin-right: 20px">
  <img width="300" src="/images/whitematter.png" alt="Also me" style="margin-left: 20px">
  <br>
  <em>Some pretty but uninformative pictures of me</em>
</p>
<br style="clear:both" />


<!-- ### Recent publications
- Blauch N, Behrmann M. (2019). Representing Faces in 3D. Nature Human Behavior.
- Blauch N, Aminoff E, Tarr MJ. (2017). Functionally localized representations contain distributed information: insight from simulations of deep convolutional neural networks. 39th Annual Proceedings of the Cognitive Science Society, London U.K.

### Recent conference abstracts
- Blauch, N., Behrmann M., Plaut, D.C. (2019). Visual Expertise and the Familiar Face Advantage. Third Annual Cognitive
Computational Neuroscience Conference, 2019. Berlin, Germany.
- Blauch, N., De Avila Belbute Peres, F., Faroqui, J., Chaman Zar, A., Plaut, D., Behrmann, M. (2019). Assessing the
Similarity of Cortical Object and Scene Perception with Cross-Validated Voxel-Encoding Models. Vision Sciences Society
Annual Meeting. St. Pete Beach, FL.
- Blauch, N., Cowell, R.A. (2018). Task Demands and Stimulus Normalization in Face Perception: an fMRI Study. Second
Annual Cognitive Computational Neuroscience Conference, 2018. Philadelphia, PA.
- Blauch, N., Aminoff, E., Tarr, M.J. (2017). Understanding Cortical Face Selectivity. First Annual Cognitive Computational
Neuroscience Conference, 2017. New York, NY. -->

<!-- ### Bio
I did my undergraduate at the University of Massachusetts, Amherst, where I developed an [individual concentration](https://www.umass.edu/bdic/aboutus) in Cognitive Computational Neuroscience and minored in Physics. As an undergrad, I worked with Dave Huber on the nROUSE model of visual priming, and developed a behavioral experiment in which participants "navigated" along trajectories in a 2D isoluminant color space. I was also lucky to spend the summer after my sophomore year studying visual masking and crowding with Denis Pelli at NYU, and the following summer working on deep network simulations with Michael Tarr at CMU. After graduation, I spent a year working as a lab manager and research associate in Rosie Cowell's computational Memory and Perception Lab, learning the ins and outs of fMRI data analysis. I then returned to CMU to begin a Ph.D in Neural Computation.   -->

<!-- <div id="images" align="center">
    <img src="/images/cnbc.png" width="45%">

    <img src="/images/CMU_Logo_Horiz_Red.png" width="45%">
</div>​ -->

<!-- This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io).

A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right.
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header.

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons.

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. -->
